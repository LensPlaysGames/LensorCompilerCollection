* Glint

Goals:
- One or many powerful, expressive type systems.
- A LISP without top level parentheses.
- Entirely My Own (You Can Fuck Off Please and Thank You, Don't "Help"; MAKE YOUR OWN).

** Shitty No-good Stinking Rotten Filthy Ideas

*** "disallow"
[2024-06-22 Sat 11:24]

It would be cool to be able to "disallow" specific variables beyond a
given point in a control flow. i.e. setup a few things and then make
them access-only after that. I guess this is sort of like const except
that you can reassign it up until it is disallowed.

#+begin_src
  foobar :string "";
  ;; ... do things
  foobar := "some other thing";
  (disallow foobar);
  ;; Fine
  printf "%s\n", foobar[0];
  ;; PROGRAM ERROR
  foobar := "mcgee mcgoo I lost my shoes";
#+end_src

*** Basic Outline
[2024-06-23 Sun 16:44]

Comma is an expression separator, semi-colon is a statement separator. Or something like that.

**** Line Comments
#+begin_example
;; This is a comment.
#+end_example

**** Variable Access
#+begin_example
foo;
#+end_example

**** Variable Declaration
#+begin_example
foo: [Byte];
#+end_example

**** Variable Declaration w/ Definition
#+begin_example
foo: [Byte] "ruh roh";
#+end_example

**** Variable Declaration w/ Definition (type inferred)
#+begin_example
foo :: "ruh roh";
#+end_example

**** Variable Assignment
#+begin_example
foo := "ruh roh";
#+end_example

**** Function Declaration w/ Immediate Return Expression
#+begin_example
func: [Byte]() "im the returned value when you call (func)";
#+end_example

**** Function Declaration w/ Body
#+begin_example
func1: [Byte]() {
  ;; .. some other stuff ..
  "im the returned value when you call (func1)";
};

;; Note that `return` also exists.
func2: [Byte](cond: Boolean) {
  if cond return "I might be the returned value, if cond is truthy";
  "im the returned value when you call (func2)";
};
#+end_example

**** Function Declaration (external)
#+begin_example
external puts: void(:byte.ptr);
#+end_example

Basically, if you are linking with a library written in another language, you can use =external= before declaring the Glint type information for the symbol from that library. Most of the time, =external= should be reserved to library wrappers/bindings written in Glint, and then =import='ed like everything else. NOTE: =external= automatically implies =export= ($\text{external} \Rightarrow \text{export} \land \text{external}$).

Defining a body expression for an externally-declared function is ill-formed.

**** Declarations (exported)
#+begin_example
;; Type-inferred Variable
export value :: 69;
;; Function
export function :int() 420;
#+end_example

NOTE: Only affects module compilation.

When compiling a module, the symbols are kept local by default. That is, the symbols defined in the generated object file(s) have a local scope/binding, meaning that when these objects are linked, other libraries and programs would not be able to access those symbols. If you are making a library and want to expose an API, put =export= behind the declaration to make it available for =import= in other Glint files (and usable in other languages via their external linkage procedures, assuming you line up the calling convention).

**** Function Call
#+begin_example
;; All of the following are equivalent.
func;
func();
(func);
#+end_example

**** Function Call w/ Arguments
#+begin_example
;; All of the following are equivalent.
func arg1, (arg_func) arg3;
func(arg1 (arg_func), arg3);
(func, arg1 (arg_func) arg3);
#+end_example

**** Struct Type Declaration
#+begin_example
my-struct: struct {
  my-member: long;
  some-data: int, ;; You can use commas or semi-colons, doesn't matter.
};
#+end_example

**** Enum Type Declaration
In Glint, an enum is just a way to name values.

#+begin_example
my-enum: enum {
  one :: 1,
  two :: 2,
};

names: enum [Byte] {
  JERRY :: "Jerry Seinfeld",
  JEREMY :: "Jeremy Elbertson",
};
#+end_example

If a type is declared, the values will be constrained to be convertible to that type.

If no type is declared, an enum will act like a union of all of the types of all of the values within it. Every enum has a corresponding sort of "variant index" stored inside it that may be queried to see what value the enum holds. Basically, each named value will be assigned an index within an enum, and then we will convert the name passed to the "enum.has" thing into the corresponding index value within the variant, allowing for the runtime check to be generated properly.

NOTE: I may choose to separate the "flag style" enum and the "variant style" enum into "enum" and "union", respectively.

#+begin_example
enum my-enum {
  one :: 1,
  two :: 2,
};

enum names :string {
  JERRY :: "Jerry Seinfeld",
  JEREMY :: "Jeremy Elbertson",
};

enum mix {
  STERMA :: "Jeremy CUCK-LORD Elbertson",
  PERMA :: 9001,
};

;; Declare variable `foo` of type `mix` initialized to value `mix.STERMA`.
foo :: mix.STERMA;

;; Reflection with .has function
if (foo.has STERMA)
  (print foo);
else if (foo.has PERMA)
  (print "It's over 9000!");

;; EVENTUALLY
switch foo {
  case STERMA (print foo);
  case PERMA (print "It's over 9000");
}
;; or even
(print {switch foo {
  case STERMA foo;
  case PERMA "It's over 9000";
}});
#+end_example

**** NOTE: Macros Are a Thing, but They Aren't Covered Here

*** Fuck Exceptions
[2024-06-23 Sun 17:50]

*** Strings Are Important
[2024-06-25 Tue 14:01]

#+begin_src lisp
  data :: "1abc2
  pqr3stu8vwx
  a1b2c3d4e5f
  treb7uchet";

  for byte :: data {
      byte;
  };
  ;; The above will expand according to the following macro (or very
  ;; similarly).
  macro
      for $sym :: $container:expr_once $body:expr
  defines i, s
  emits
      s :: $container.end;
      cfor {
          i :: container.begin;
          i < s;
          ++i;
      } {
          $sym :: $container[i];
          $body;
      };
  endmacro

  for line :: data.lines {
      for byte :: line {
          byte;
      };
  };
  ;; The above should expand to the following (roughly)
  s :: data.lines.end;
  cfor {
      i :: data.lines.begin;
      i < s;
      ++i;
  } {
      byte :: data.lines[i];
      ;; ... body from outer `for` inserted here ...
      for byte :: line {
          byte;
      };
  };
#+end_src

Note that due to deproceduring, it is possible for this for to either call functions or access values without special handling required for those cases.

*** AOC 2023 Day 1
[2024-06-25 Tue 14:22]

#+begin_src lisp
  data :: "1abc2
    pqr3stu8vwx
    a1b2c3d4e5f
    treb7uchet";

  sum :: 0;

  first-digit-present :: false;
  first-digit-value :: 0;
  last-digit-value :: 0;
  for byte :: data {
      if byte = '\n' {
          first-digit-present := false;
          line-value :: 10(first-digit-value) + last-digit-value;
          sum += line-value;
      } else if (one-of "0123456789" byte) {
          last-digit-value := byte - 48;
          if not first-digit-present {
              first-digit-present := true;
              first-digit-value := byte - 48;
          };
      };
  };
  line-value :: 10(first-digit-value) + last-digit-value;
  sum += line-value;

  sum;
#+end_src

*** Sequences
[2024-06-25 Tue 14:24]

I guess the idea is that anything iterable will fit an interface called a Sequence, and that a lot of things built-in to the language and standard library will operate on sequences. This will handle linked lists (the most important data structure, /clearly/), dynamic arrays, strings, and more.

Something important is that a user-defined type (i.e. a struct) may meet the standards of a sequence, and therefore integrate tightly with the inner workings of the language.

*** AoC 2023 Day 2 :: Data
[2024-06-25 Tue 14:38]

#+begin_src lisp
  struct Game {
      id :: 0;
      struct CubeCount {
          red :: 0;
          green :: 0;
          blue :: 0;
      };
      records: [CubeCount];
  };

  games :: ([Game]
      (Game 1
       ([CubeCount]
        (CubeCount 4 0 3)
        (CubeCount 1 2 6)
        (CubeCount 0 2 0)))
      (Game 2
       ([CubeCount]
        (CubeCount 0 2 1)
        (CubeCount 1 3 4)
        (CubeCount 0 1 1)))
      (Game 3
       ([CubeCount]
        (CubeCount 20 8 6)
        (CubeCount 4 13 5)
        (CubeCount 1 5 0)))
      (Game 4
       ([CubeCount]
        (CubeCount 3 1 6)
        (CubeCount 6 3 0)
        (CubeCount 14 3 15)))
      (Game 5
       ([CubeCount]
        (CubeCount 6 3 1)
        (CubeCount 1 2 2)))
  );

  possible_games_id_sum :: 0;
  for game :: games {
      possible :: true;
      for count :: game.records {
          if count.red > 12 or count.green > 13 or count.blue > 14 {
              possible := false;
              (break);
          }
      }
      if possible possible_games_id_sum += game.id;
  }
  possible_games_id_sum;
#+end_src

Basically, I'm trying to show here a couple things:
- Invoking a type constructs an instance of that type
- Built-in Dynamic Arrays
May we eventually have a very capable standard library that may even have a dynamic array container type that is easier to maintain and also easier to use? Yes. But that's a long ways off, and I want it to be *easy* to have a dynamic list right off the bat (otherwise implementing that standard library will be /rough/).

*** Some Types
[2024-06-25 Tue 15:07]

**** Base Built-in Types

uX where X is any decimal integer -> arbitrary-bitwidth unsigned integer
sX where X is any decimal integer -> arbitrary-bitwidth signed integer
Byte
Bool, bool, Boolean, boolean -> Bool
String, Symbol -> String -> [Byte]

**** Type Modifiers, Complex Types

[T] -> Dynamic Array of T
T() -> Function w/ Return Type T
T.ptr -> Pointer to T

*** Lexer Macros
[2024-06-25 Tue 15:22]

You know LaTeX? Yeah, like that.

**** Simple Macro
#+begin_example
macro add34 $arg1 emits
  $arg1 + 34
endmacro

add34 35
#+end_example

This defines a macro called =add34= which takes a single macro argument; *remember, macro arguments are tokens at the lexer level*, unless otherwise specified. When a macro is expanded, any uses of the macro argument in the output, in the macro expansion, will be replaced with the token passed when invoking the macro. This means the =add34 35= macro invocation expands into =35 + 34=. Notice how there is no macro left in the final code; they are purely tools to generate code, not code itself.

**** Hygienic Macros
#+begin_example
macro increment $i emits {
  a :: 0
  $i := $i + 1
} endmacro

a :: 4
b :: 8
increment a
increment b
a
#+end_example

The above will error, complaining about the macro =increment= not being hygienic in the expansion of =increment a=. That's right, no crazy macro shadowing issues like in C.

The proper way to declare a new variable within a macro is to generate a unique symbol to use by using =gensym=.
#+begin_example
macro increment $i
defines a ;; <---- the important part
emits {
  a :: 0
  $i := $i + 1
  a := 42
  $i
} endmacro

a :: 67
increment a
increment a
#+end_example

By letting the compiler know that a symbol within the macro is meant to be unique to each invocation of the macro, it may generate a unique symbol and replace uses of the original symbol with the unique one.

In case you aren't familiar: [[https://en.wikipedia.org/wiki/Hygienic_macro]]

**** Empty Macro
#+begin_example
macro foo emits endmacro
foo
#+end_example

**** Macro Selector =expr=
#+begin_example
macro capture_binary $binop:expr emits
  $binop + $binop
endmacro

1 + capture_binary 17 + 17
#+end_example

Because these macros work at the level of the lexer, it can be really difficult to work with values at the language level, at the parser level. To fix this, we have the =expr= selector. This may be applied to any macro argument, and it will change how tokens are bound to the argument. Instead of binding the argument to the first token found, it will bind the argument to the first expression parsed. As you can see above, this is useful to be able to capture values at the language level rather than individual tokens.

You may be asking, how does this even work? Well, the lexer has a token type that is a node the parser returns. We parse an expression and store the result in a token, as weird as that is.

**** Macro Selector =expr_once=
#+begin_example
variable :: 0
foo : int() {
  variable := variable + 1
  33 + variable
}

macro doubled $a:expr_once emits
  $a + $a
endmacro

doubled foo() ;; returns 68
#+end_example

Basically, if you expand a single input token multiple times in the output of a macro, /and that input token evaluates to something that has side effects/, those side effects may occur multiple times and that may not be the behavior necessary. For this, we have the =expr_once= selector. It is much like the =expr= selector, except that even if the expression is expanded multiple times, it is only ever evaluated once.

This is accomplished by caching the return value in a variable with a generated, unique symbol and then replacing all expansions of the original expression with that unique symbol.

*** Parser Macros
[2024-06-25 Tue 15:22]

If you've written macros in LISP, that is what I'm talking about.

Basically, these sort of macros will be "real code", but the catch is that it is run at compile-time and generates code itself that is then evaluated in the final code. Again, if you haven't written LISP macros this might sound confusing, but it's actually really simple (and incredibly powerful in turn) once you get the hang of it.

#+begin_src lisp
  (defmacro foo (a b c)
    (if (= a "sum")
        `(+ ,b ,c)
        `(- ,b ,c)))
#+end_src

Hopefully you can read LISP, as I don't yet have a syntax worked out in Glint.

The above defines a macro =foo= with three macro arguments, =a=, =b=, and =c=.

The macro body is an =if= control flow expression.

So, what exactly happens when we invoke the macro?
#+begin_src lisp
  (foo "difference" 70 1)
#+end_src

Well, /at compile time/, the macro body is expanded and then run, resulting, in this case, in =(- 1 70)= being returned. Now, you might be a bit weirded out at this point... the macro returned /more code/. And that's exactly the key to these types of macros: their return value is the code that they will expand into. In the final code, it is as if we erased the macro invocation and inserted the return value of that invocation in it's place.

Helpful NOTE: While quasiquoting sounds fancy and people choose to make it hard to understand (by refusing to because words are new and/or different to what they are used to, /grrr/), it is actually as simple as string interpolation.

#+begin_src lisp
(setq foo "69")
`("abc" ,foo "def")
#+end_src
The above quasiquotation with an unquote is equivalent to the following string interpolation.
#+begin_src js
const foo = "69";
`abc${foo}def`;
#+end_src

If you can't wrap your heads around quasiquoting, it's a /you/ problem :&.

*** A String Should Be Able to Be Used as a Symbol
[2024-06-25 Tue 15:50]

A =String= should be able to be used in the same ways a symbol can, or converted between the two. While this isn't possible with a String who's value is not known at compile time (unless we implement some sort of Glint environment with a runtime, but that doesn't sound like my style), it /is/ possible for values known at compile time---for example those often passed to macro invocations. The idea is that we may eventually have a parser macro that takes or makes a String, possibly does things to it, then uses that to return code that accesses a variable bound to a symbol equivalent to the contents of that String...

*** =unless= (no else allowed) and =until=
[2024-06-25 Tue 16:46]

The opposites of =if= and =while=, they're there if you want them.

=unless=
#+begin_src lisp
  success :: do_something_that_might_fail();
  unless success {
      (print "something went horribly wrong\n");
      (exit 1);
  };
#+end_src

=until=
#+begin_src lisp
  data :: "Some \"string\" returned from some C library\n";
  c_str :: data[0];
  until @c_str = '\0' {
      (print @c_str);
      c_str := c_str[1];
  };
#+end_src

*** Function Overloading
[2024-06-26 Wed 01:28]

I am not against it, but I don't often use it. It's a nice-to-have and for the amount of work it takes to implement, I'm not super focused on getting this in particular working.

*** The Focus
[2024-06-27 Thu 12:42]

I just want to clarify what should be a focus in the design of Glint: strings and dynamic arrays ("vectors"). Specifically, /native/ and /extensible/ strings and dynamic arrays, and operations on them.

In my opinion, having these two things makes implementing just about anything much, much easier and faster. At the same time, making the user implement these things themselves is one of the most common avenues to bugs, memory corruption, and more.

*** Multiple Strings? Nah
[2024-06-27 Thu 17:36]

I want multiple string literals in a row to become a single string literal.

*** Reduction Rules
[2024-07-02 Tue 10:06]

String <- String, [String];

Call F(x...) <- F x...;

*** Parser Macro Syntax Playground
[2024-07-02 Tue 10:06]

Attempt 001 (=cmacro= return type)
#+begin_src lisp
  ;; If you aren't used to parser macros, it is code that runs at compile
  ;; time to return code that will be compiled into the final program.
  ;; Think of it like code that operates on code instead of data.
  plus : cmacro(nodes : [Node]) {
    out :: (NodeBinaryAdd 0 0);
    for node :: nodes {
      out.left := node;
      out.right := (NodeBinaryAdd 0 0);
      out := out.right;
    };
    out;
  };

  (plus 34 35);
  ;; MACRO-INVOCATION plus NODES 34 35
  ;; expansion steps:
  ;; 0 + 0
  ;; 34 + 0
  ;; 34 + (0 + 0)
  ;; 34 + (35 + 0)
  ;; 34 + (35 + (0 + 0))
  ;; 34 + 35 + 0 + 0
#+end_src

While this does make =cmacro= a keyword, I really don't think that's an issue. I'm okay with a thousand keywords, honestly. The above =plus= macro doesn't require any quasiquoting or any of the more complex evaluation requirements that some parser macros have; I've also written it to be simple rather than perfectly efficient. This is just to play with the syntax, mind you.

*** =embed "foo.bin";=
[2024-07-02 Tue 10:18]

Yes, like the new =C= standards, we will have data embeds that also adhere to include paths. I'm pretty sure we'll just have this create a fixed =Byte= array, and have it able to be used in initialisers.

*** New Overview/Outline
[2024-07-03 Wed 07:47]

#+begin_example
Variable Access :: IDENTIFIER
Variable Declaration
 :: IDENTIFIER "::" init-value
 :: IDENTIFIER ":" type
 :: IDENTIFIER ":" type init-value
Variable Assignment :: IDENTIFIER ":=" new-value
Lambda :: "lambda" function-type body-expr;
Function Call :: function [ args... ];
Typed Compound Literal :: type [ args... ];
Compound Literal :: "!{" [ args... ] "}";

Control Flow CFor :: "cfor" "(" init-expr; condition-expr; iterator-expr; ")" body-expr;
Control Flow while :: "while" condition-expr body-expr;
Control Flow until :: "until" condition-expr body-expr;
Control Flow if :: "if" condition-expr body-expr;
if-else Expression :: "if" condition-expr body-expr "else" body-expr;

Binary Member Access :: "."
Binary Subscript :: array "[" index "]"
Binary Dereferencing Access :: pointer "->" IDENTIFIER
Binary Add :: "+"
Binary Sub :: "-"
Binary Mul :: "*"
Binary Div :: "/"
Binary Equals :: "="
Binary Logical And :: "and"
Binary Logical Or :: "or"
Binary Bitwise And :: "&&"
Binary Bitwise Or :: "||"
Binary Bitwise Xor :: "xor"
Binary Bitwise Shift Left :: "shl"
Binary Bitwise Shift Right, Signed :: "sar"
Binary Bitwise Shift Right, Unsigned :: "shr"

Unary Prefix Logical Not :: "not"
Unary Prefix Bitwise Not :: "~"
Unary Prefix Pointer Dereference :: "@"
Unary Prefix sizeof :: "sizeof"
Unary Prefix alignof :: "alignof"

File Embed :: "embed" file-path;

Type void
Type bool, Bool, boolean, Boolean
Type Byte
Type String, Symbol
Type Arbitrary Signed Int :: "s" INTEGER
Type Arbitrary Unsigned Int :: "u" INTEGER
Type Default Signed Int :: "int" -> ssize_t
Type Default Unsigned Int :: "uint" -> size_t
Type Modifier Array :: "[T]", "[T size]"
Type Modifier Pointer To :: "T.ptr"
Type Modifier Reference :: "T.ref"
Type Modifier Function :: "T()"

Lexer Macro
Parser Macro

IDENTIFIER :: The usual
INTEGER :: The usual
#+end_example

Ambiguities that have been resolved:
- By changing array syntax from =T[size]= to =[T size]=, subscripts of values and arrays of arbitrary types are now parseable into single trees.

I guess type casting will be equivalent to instantiating that type (compound literal), where we just call the type like it's a function, i.e. =(T v)=.

*** Lambda
[2024-07-03 Wed 09:37]

#+begin_src lisp
  (lambda T() ...body)
#+end_src

NOTE: I wonder if, with the (T v) parsing syntax, we could just have =T() body-expr= be a lambda? Not needed, and I'll start with just the lambda keyword, but it's something to think about ... when else would a function type not be followed immediately by a semi-colon? Also would make the lambda syntax the same as normal function syntax, just without the =name:= preceding it.

*** Unary Minus to Free Dynamic Array
[2024-07-03 Wed 17:26]

#+begin_src lisp
  foo : [Byte 4];
  ;; ... use foo
  -foo;
  ;; if foo is used "from here on", after the free, the compiler should
  ;; issue an error. NOTE: what if -foo is in body of while, etc.
#+end_src

Maybe also unary plus to allocate a type, i.e. =+T= in Glint -> =new T();= in C++.
#+begin_src lisp
  ;; NOTE: Type of bar is Byte.ptr (return type of allocation function).
  bar : +Byte;
  ;; ... use bar
  -bar;
#+end_src

I dunno, doesn't seem like the worst thing in the world. But it also does. Lol. Allocation will always suck, afaik.

*** Print
[2024-07-04 Thu 14:20]

#+begin_src lisp
  print 42;        ;; -> 42
  print "42";      ;; -> 42
  print (cchar 42); ;; -> *
#+end_src

EVENTUALLY we will want a way to do /something like/ string interpolation (probably generalized to work on any dynamic array, just for fun).

*** "Character"
[2024-07-04 Thu 20:10]

While we don't have a char type like C does, and our strings take advantage of both single and double quotes anyway, we do have a short-hand syntax for converting a string /literal/ into it's corresponding byte value using the =b= prefix.
#+begin_src lisp
  "hello"; ;; type of [Byte], value of "hello"
  b"hello"; ;; ERROR: too many bytes in bytestring being converted into byte value.
  b"h"; ;; type of Byte, value of 104
#+end_src

*** Small Note
[2024-07-04 Thu 20:45]

Equivalent:
#+begin_src lisp
  ;; Type-declared variable declaration initialized with integer literal.
  offset : usz 0;
  offset : usz = 0;
  ;; Type-inferenced variable declaration initialized with compound literal.
  offset :: usz 0;
#+end_src

NOTE: May end up removing ability to put ~=~ in there.

*** "Pincer" Type Inference
[2024-07-04 Thu 20:48]

NOTE: This may all be really stupid, or not novel, or something like that. That's okay.

Fuck bottom-up and top-down closed-off stupid mindsets. Like the parsers I write, both will be used in tandem. My idea is that sometimes when we are type-checking we will have an "expected type": this is the top-down approach, I think.

Type-checking the initialising expression of =offset : usz -1;=, for example, we can pretty heavily infer that the type should be a usz: we don't need the initialising expression to explicitly declare it's own type (i.e. bottom up). Not that it couldn't, of course: a value may absolutely have it's type fully defined. This is the approach of the pincer: it aims to find places where it can't pinch, and those are errors. That is, it tries to find places where the /defined type/ of an expression (bottom-up) isn't convertable to the /declared type/ of an expression (top-down); these are type errors.

Why does this matter? Well, if you have ever used C, you will recognized the declaration above and realise that, in C, as soon as you compile it, you will get a big, phat warning (provided =-Wconversion= is on, but, if it isn't, /you are insane/), or maybe even an error. This is because =-1=, as an expression by itself, is signed. I mean, if it wasn't, the sign wouldn't be doing much there, would it :Ãž? So, the expression itself defines it's type to be some signed integer type (or at least constrains it so), and the declaration declares it's value to be of an unsigned integer type. As you can see, this mismatch is what causes the type warnings/errors to occur in C. However, looking at this from a philosophical point of view, what did the programmer intend in writing such syntax? THEY OBVIOUSLY INTENDED TO INITIALISE A =usz= WITH A VALUE OF =-1= AND HAVE ASKED THE LANGUAGE AND/OR COMPILER TO DO THE CONVERSION AUTOMATICALLY. Like, really, what kind of programmer is relying on a compiler to tell them they initialised something to a value that has to be converted to what they are initialising it to? I understand they ideally want no operation to happen "silently" in C or whatever but in C++... yeah, I don't know why they keep this system around. So, instead of having a perfectly-precise pincer-point that may only effectively "pinch" when they are exactly the same, I want to put some leeway in there to /trust the programmer/ and therefore bias the pincer towards the top-down declared type if present (converting the value of bottum-up defined type to the declared type if necessary). This means no error on things like =offset : usz -1=. the compiler will insert a cast/conversion to =usz=, and store that value.

C++ people may argue that this is a problem because it does conversions that might be costly very easily and invisibly, or something like that. My response to that is that if a programmer cares about performance, they will write performant code, and know how to do so. If our goal was to allow any old idiot to write perfectly fast code, then, sure, we may want to make it obvious that expensive operations occur when creating a string from a string view or something of that nature, and make it difficult to do in the first place---to try and force programmers who don't care about performance to write performant code when it may not even matter for the program they are writing. In my opinion, this is /futile/. If a programmer's program runs too slow, /they/ will figure out why and fix up that code; if that programmer was converting between string view and string all the time, or making a bunch of dynamic array copies, or whatever other awfulness they have stumbled upon, then they will learn a valuable lesson in how /not/ to write code as well as the consequences if you do.

*** Dynamic Arrays
[2024-07-06 Sat 19:59]

**** Initialisation

#+begin_src lisp
  foo: [Byte];
  ;; should be equivalent to
  foo_t : struct {
      data: Byte.ptr;
      size: int;
      capacity: int;
  };
  foo: foo_t;
  foo.size := 0;
  foo.capacity := 8;
  foo.data := malloc 8(sizeof Byte);
#+end_src

**** Appending

1. Grow if new size would exceed or equal current capacity.
2. Write appended value.
3. Update size.

#+begin_src lisp
  foo: [Byte];

  foo += 42;
  ;; should be equivalent to
  ;; (grow if needed)
  if foo.size + 1 >= foo.capacity {
      foo.capacity *= 2;
      foo.data := realloc foo.data foo.capacity;
  }
  ;; (write new value)
  @foo.data[foo.size] := 42;
  ;; (update size)
  foo.size += 1;
#+end_src

My main question right now is that I'm not entirely sure where these things should be implemented, i.e. during Parsing or during IRGen.

*** ptr ptr
[2024-07-08 Mon 23:03]

cadr cdar, ptr pptr

#+begin_src c
  argv: Byte.ptr.ptr
#+end_src

Yeah, that's not gonna fly.

#+begin_src c
  argv: Byte.pptr
#+end_src

Yeah, that makes a lot of sense.

For people who need a pointer to a pointer to a pointer... what in the fuck are you doing? Write it out if you need to be that crazy.
